#!/usr/bin/env python3
# -*- coding:utf-8 -*-

import os
import signal
import argparse
import json
import tempfile
import shutil
import tarfile
import codecs
import uuid
from agora_results.pipes.base import Pipe
from agora_results.pipes import PipeReturnvalue

DEFAULT_PIPELINE = [
    [
      'agora_results.pipes.results.do_tallies',
      {}
    ],
    [
      "agora_results.pipes.sort.sort_non_iterative",
      {
        "question_indexes": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
      }
    ]
]

# By default we only allow the most used pipes to reduce default attack surface
# NOTE: keep the list sorted
DEFAULT_PIPES_WHITELIST = [
    #"agora_results.pipes.duplicate_questions.duplicate_questions",
    "agora_results.pipes.modifications.apply_modifications",
    #"agora_results.pipes.multipart.make_multipart",
    #"agora_results.pipes.multipart.election_max_size_corrections",
    #"agora_results.pipes.multipart.question_totals_with_corrections",
    #"agora_results.pipes.multipart.reduce_answers_with_corrections",
    #"agora_results.pipes.multipart.multipart_tally_plaintexts_append_joiner",
    #"agora_results.pipes.multipart.data_list_reverse",
    #"agora_results.pipes.multipart.multipart_tally_plaintexts_joiner",
    #"agora_results.pipes.multipart.append_ballots",
    "agora_results.pipes.parity.proportion_rounded",
    "agora_results.pipes.parity.parity_zip_non_iterative",
    #"agora_results.pipes.parity.reorder_winners",
    #"agora_results.pipes.parity.podemos_parity_loreg_zip_non_iterative",
    #"agora_results.pipes.podemos.podemos_proportion_rounded_and_duplicates",
    #"agora_results.pipes.pretty_print.pretty_print_stv_winners",
    "agora_results.pipes.pretty_print.pretty_print_not_iterative",
    "agora_results.pipes.results.do_tallies",
    #"agora_results.pipes.results.to_files",
    #"agora_results.pipes.results.apply_removals",
    "agora_results.pipes.sort.sort_non_iterative",
    #"agora_results.pipes.stv_tiebreak.stv_first_round_tiebreak"
]

def extract_tally(fpath):
    '''
    extracts the tally and loads the results into a file for convenience
    '''
    extract_dir = tempfile.mkdtemp()
    tar = tarfile.open(fpath)
    tar.extractall(extract_dir)
    tar.close()
    return extract_dir

def print_csv(data, separator):
    counts = data['results']['questions']
    for question, i in zip(counts, range(len(counts))):
        if question['tally_type'] not in ["plurality-at-large", "borda", "borda-nauru"] or\
           question.get('no-tally', False):
            continue

        print(separator.join(["Question"]))
        print(separator.join(["Number", "Title"]))
        print(separator.join([str(i + 1), question['title']]))
        print(separator*2)

        print(separator.join(["Totals"]))

        question_total = (question['totals']['null_votes']
            + question['totals']['blank_votes']
            + question['totals']['valid_votes'])

        print(separator.join(["Total votes", str(question_total)]))
        print(separator.join(["Blank votes", str(question['totals']['blank_votes'])]))
        print(separator.join(["Null votes", str(question['totals']['null_votes'])]))
        print(separator.join(["Valid votes", str(question['totals']['valid_votes'])]))
        print(separator*2)

        print(separator.join(["Answers"]))
        print(separator.join(["Id", "Text", "Category", "Total votes", "Winner position"]))
        for answer in question['answers']:
            print(separator.join([
                str(answer['id']),
                answer['text'],
                answer['category'],
                str(answer['total_count']),
                str(answer['winner_position'])]))


def pretty_print(data):
    from agora_results.pipes.pretty_print import pretty_print_not_iterative
    pretty_print_not_iterative([data])

def print_results(data, output_format):
  '''
  print results in the specified output format
  '''
  if output_format == "json":
    print(json.dumps(
        data['results'],
        indent=4,
        ensure_ascii=False,
        sort_keys=True,
        separators=(',', ': ')))
  elif output_format == "csv":
      print_csv(data, separator=",")
  elif output_format == "tsv":
      print_csv(data, separator="\t")
  elif output_format == "pretty":
      pretty_print(data)

def class_path_sanity_checks(class_path, pipes_whitelist):
    '''
    Check that the class path is valid and reasonably secure
    '''
    if pipes_whitelist is not None and class_path not in pipes_whitelist:
        raise Exception("Pipe not in the whitelist: %s" % class_path)

    values = class_path.split(".")
    if " " in class_path or len(values) == 0 or len(values) > 4 or\
        values[0] != "agora_results" or values[1] != "pipes":
        raise Exception()

    for val in values:
        if len(val) == 0 or val.startswith("_"):
            raise Exception()

def check_pipeline_conf(pipeline_conf, name):
    '''
    Check configuration of each pipe
    '''
    pipeline_pipes = Pipe.get_pipes(name)
    for class_path, pipe_conf in pipeline_conf:
        class_name = class_path.split(".")[-1]
        pipeline_pipes[class_name].check_config(pipe_conf)

def register_pipes(pipeline_conf, name):
    '''
    Register each pipe on a pipeline
    '''
    for class_path, kwargs in pipeline_conf:
    # get access to the function
        class_name = class_path.split(".")[-1]
        module = __import__(
            ".".join(class_path.split(".")[:-1]), globals(), locals(),
            [class_name], 0)
        imported_class = getattr(module, class_name)
        Pipe.register_pipe(imported_class, name)

def execute_pipeline(pipeline_conf, data_list, name, pipes_whitelist=None):
    '''
    Execute a pipeline of options. pipeline_conf must be a list of
    pairs. Each pair contains (pipe_class_path, params), where pipe_class_path is
    the path to the module and a class name, and params is either
    None or a dictionary with extra parameters accepted by the class.

    Method execute of pipeline classes must accept always at least one parameter, 'data', which
    will initially be the data parameter of this class, but each pipe class is
    allow to modify it as a way to process the data.

    The other parameters of the method execute will be the "params" specified for
    that function in 'pipeline_conf', which can either be None or a dict, and
    the format is of your choice as a developer.
    '''   
    valid_pipes = Pipe.get_pipes(name)

    for class_path, pipe_conf in pipeline_conf:
        class_path_sanity_checks(class_path, pipes_whitelist)
        pipe_name = class_path.split(".")[-1]
        ret = valid_pipes[pipe_name].execute(data=data_list, config=pipe_conf)
        if ret != PipeReturnvalue.CONTINUE:
            return ret

    return PipeReturnvalue.CONTINUE

def read_file(path):
    with codecs.open(path, 'r', encoding="utf-8") as f:
        return f.read()

def write_file(path, data):
    with codecs.open(path, 'w', encoding="utf-8") as f:
        f.write(data)

def serialize(data):
    return json.dumps(data,
        indent=4, ensure_ascii=False, sort_keys=True, separators=(',', ': '))

def create_ephemeral_tally(econfig_path):
    '''
    Creates a tally in a temporal directory from an election config
    '''
    tmp_dir = tempfile.mkdtemp()
    econfig_txt = read_file(econfig_path)
    econfig = json.loads(econfig_txt)

    write_file(
        os.path.join(tmp_dir, "questions_json"),
        serialize(econfig["questions"]))

    for i in range(len(econfig["questions"])):
        session_id = "%d-%s" % (i, str(uuid.uuid4()))
        os.mkdir(os.path.join(tmp_dir, session_id))
        write_file(os.path.join(tmp_dir, session_id, "plaintexts_json"), "")

    return tmp_dir

def main():
    parser = argparse.ArgumentParser(description='Process and show tally '
                                     'results. If no config is specified, it '
                                     'parses results in raw.')
    parser.add_argument('-t', '--tally', nargs='*', help='tally path', default=[])
    parser.add_argument('-e', '--election-config', nargs='*', help='Instead of specifying a tally, you can specify an json election config and an empty ephemeral tally with zero votes will be created. recommended to use together with the multipart.append_ballots pipe.', default=[])
    parser.add_argument('-x', '--tar',   nargs='?', help='tar tallies output path')
    parser.add_argument('-p', '--pipes-whitelist', help='path to the file containing the allowed pipes')
    parser.add_argument('-c', '--config', help='config path')
    parser.add_argument('-s', '--stdout', help='print output to stdout',
        action='store_true')
    parser.add_argument('-o', '--output-format', help='select the output format',
        default="json", choices=["json", "csv", "tsv", "pretty", "none"])
    pargs = parser.parse_args()

    # load config
    if pargs.config is not None:
      with codecs.open(pargs.config, 'r', encoding="utf-8") as f:
          pipeline_conf = json.loads(f.read())
    else:
      pipeline_conf = DEFAULT_PIPELINE

    # load allowed pipes: Format of the file should simply be: one pipe per line
    if pargs.pipes_whitelist is not None:
        with codecs.open(pargs.pipes_whitelist, 'r', encoding="utf-8") as f:
            pipes_whitelist = [l.strip() for l in f.readlines()]
    else:
      pipes_whitelist = DEFAULT_PIPES_WHITELIST

    data_list = []

    # remove files on abrupt external exit signal
    def sig_handler(signum, frame):
        if not pargs.stdout:
            print("\nTerminating: deleting temporal files..")
        for data in data_list:
            if os.path.exists(data["extract_dir"]):
                shutil.rmtree(data["extract_dir"])
        exit(1)
    signal.signal(signal.SIGTERM, sig_handler)
    signal.signal(signal.SIGINT, sig_handler)

    try:
        if len(pargs.tally) == 0 and len(pargs.election_config) == 0:
            print("You need to specify at least one tally or election-config")
            exit(1)

        if len(pargs.tally) > 0 and len(pargs.election_config) > 0:
            print("You can't specify both a tally and an election-config")
            exit(1)

        if len(pargs.election_config) > 0:
            for econfig_path in pargs.election_config:
                tmp_dir = create_ephemeral_tally(econfig_path)
                if not pargs.stdout:
                    print("Ephemeral tally for config %s in %s.." %
                        (econfig_path, tmp_dir))
                data_list.append(dict(extract_dir=tmp_dir))
        else:
            # extract each tally, before starting the pipeline, and put the tally
            # relevant data in a list that is processed by the pipeline
            for tally in pargs.tally:
                extract_dir = extract_tally(tally)
                if not pargs.stdout:
                    print("Extracted tally %s in %s.." % (tally, extract_dir))
                data_list.append(dict(extract_dir=extract_dir))
                
        register_pipes(pipeline_conf, 'register-pipeline') # register pipes necessary                
        check_pipeline_conf(pipeline_conf, 'register-pipeline') # check pipeline configuration
        execute_pipeline(pipeline_conf, data_list, 'register-pipeline',
                         pipes_whitelist=pipes_whitelist) # execute pipeline
        
        if pargs.stdout and len(data_list) > 0 and 'results' in data_list[0]:
          print_results(data_list[0], pargs.output_format)
        data = ""

        # tar tallies
        if pargs.tar:
            from agora_results.utils.tallies import tar_tallies
            for tally in pargs.tally:
                tar_tallies(data_list[0], pipeline_conf, tally, pargs.tar)

    finally:
        if not pargs.stdout:
            print("Deleting temporal files..")
        for data in data_list:
            if os.path.exists(data["extract_dir"]):
                shutil.rmtree(data["extract_dir"])

if __name__ == '__main__':
    main()
